{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❗❗❗Внимание❗❗❗\n",
    "### Данный ноутбук составлял участник нашей команды вне окружения проекта.\n",
    "\n",
    "### Здесь используется нестандартное окружение, в связи с этим, вероятно возникнут трудности с запуском.\n",
    "\n",
    "### Ноутбук предоставляется «как есть» и не несет важной составляющей инференса или обучения моделей.\n",
    "\n",
    "### Для работы может потребоваться установка дополнительных библиотек и настройка окружения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Iterable, Callable, Any, Optional, Literal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.join(current_dir, '..')\n",
    "sys.path.append(parent_dir)\n",
    "import scripts.utils.net as net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = None\n",
    "\n",
    "IMAGE_DATASET_DIR = r\"..\\image_dataset\"                     # путь к датасету в виде пар фотографий\n",
    "\n",
    "CHECKPOINT_PATH = r\"..\\ckpt_eer_epoch2_batch209000.ckpt\"    # путь к весам модели\n",
    "\n",
    "FGSM_SAVE_DIR = r\"\\check_attack_score\"                      # путь к папке для сохранения датасета с FGSM атакой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "aligner_path = os.path.expanduser('~/.cvlface_cache/minchul/cvlface_DFA_resnet50')\n",
    "aligner_repo = 'minchul/cvlface_DFA_resnet50'\n",
    "\n",
    "adaface_models = {\n",
    "    'ir_101': CHECKPOINT_PATH\n",
    "}\n",
    "\n",
    "test_dir = IMAGE_DATASET_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция для загрузки модели-выравнивателя с HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(repo_id: str, path: str, HF_TOKEN: Optional[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    :param repo_id: ID репозитория на Hugging Face.\n",
    "    :param path: Локальный путь для сохранения файлов.\n",
    "    :param HF_TOKEN: Токен аутентификации (если требуется).\n",
    "    \"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    files_path = os.path.join(path, 'files.txt')\n",
    "    \n",
    "    if not os.path.exists(files_path):\n",
    "        hf_hub_download(\n",
    "            repo_id, 'files.txt', token=HF_TOKEN, \n",
    "            local_dir=path, local_dir_use_symlinks=False\n",
    "        )\n",
    "    \n",
    "    with open(files_path, 'r', encoding='utf-8') as f:\n",
    "        files = f.read().splitlines()\n",
    "    \n",
    "    additional_files = ['config.json', 'wrapper.py', 'model.safetensors']\n",
    "    \n",
    "    for file in [f for f in files if f] + additional_files:\n",
    "        full_path = os.path.join(path, file)\n",
    "        if not os.path.exists(full_path):\n",
    "            hf_hub_download(\n",
    "                repo_id, file, token=HF_TOKEN, \n",
    "                local_dir=path, local_dir_use_symlinks=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка модели из локального пути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_local_path(path: str, HF_TOKEN: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    :param path: Путь к модели.\n",
    "    :param HF_TOKEN: Токен аутентификации (если требуется).\n",
    "    :return: Загруженная модель.\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(path)\n",
    "    sys.path.insert(0, path)\n",
    "    \n",
    "    model = AutoModel.from_pretrained(path, trust_remote_code=True, token=HF_TOKEN)\n",
    "    \n",
    "    os.chdir(cwd)\n",
    "    sys.path.pop(0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка модели по идентификатору репозитория."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_by_repo_id(repo_id: str, save_path: str, HF_TOKEN: Optional[str] = None, force_download: bool = False):\n",
    "    \"\"\"\n",
    "    :param repo_id: ID репозитория на Hugging Face.\n",
    "    :param save_path: Путь для сохранения модели.\n",
    "    :param HF_TOKEN: Токен аутентификации (если требуется).\n",
    "    :param force_download: Принудительная загрузка (удаляет существующую директорию перед загрузкой).\n",
    "    :return: Загруженная модель.\n",
    "    \"\"\"\n",
    "    if force_download and os.path.exists(save_path):\n",
    "        shutil.rmtree(save_path)\n",
    "    \n",
    "    download(repo_id, save_path, HF_TOKEN)\n",
    "    return load_model_from_local_path(save_path, HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка предобученной модели указанной архитектуры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(architecture: Literal['ir_101'] = 'ir_101'):\n",
    "    \"\"\"\n",
    "    :param architecture: Название архитектуры модели (по умолчанию 'ir_101').\n",
    "    :return: Загруженная и подготовленная к использованию модель.\n",
    "    \"\"\"\n",
    "    assert architecture in adaface_models, f\"Архитектура {architecture} не поддерживается.\"\n",
    "    \n",
    "    model_ = net.build_model(architecture)\n",
    "    statedict = torch.load(\n",
    "        adaface_models[architecture], map_location=torch.device('cpu')\n",
    "    )['model_state_dict']\n",
    "    \n",
    "    model_.load_state_dict(statedict)\n",
    "    model_.eval()\n",
    "    \n",
    "    return model_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка состояния модели, оптимизатора и планировщика обучения из чекпоинта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(\n",
    "    filepath: str, \n",
    "    model: torch.nn.Module, \n",
    "    optimizer: Optional[torch.optim.Optimizer] = None, \n",
    "    scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None\n",
    ") -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    :param filepath: Путь к файлу чекпоинта.\n",
    "    :param model: Модель, в которую загружается состояние.\n",
    "    :param optimizer: Опционально, оптимизатор для загрузки состояния.\n",
    "    :param scheduler: Опционально, планировщик обучения для загрузки состояния.\n",
    "    :return: Модель с загруженными весами.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(filepath, map_location=torch.device('cpu'))\n",
    "    \n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    \n",
    "    if optimizer is not None and \"optimizer_state_dict\" in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    \n",
    "    if scheduler is not None and \"scheduler_state_dict\" in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "    \n",
    "    epoch = checkpoint.get(\"epoch\", -1)\n",
    "    global_batch = checkpoint.get(\"global_batch\", -1)\n",
    "    \n",
    "    print(f\"Загружен чекпоинт: эпоха {epoch}, глобальный батч {global_batch}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка предобученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружен чекпоинт: эпоха 2, глобальный батч 209000\n"
     ]
    }
   ],
   "source": [
    "model = load_pretrained_model('ir_101').to(device)\n",
    "model = load_checkpoint(CHECKPOINT_PATH, model).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование PIL-изображение (RGB) в тензор для модели AdaFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_input(pil_rgb_image: Image.Image) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :param pil_rgb_image: Входное изображение формата PIL (RGB).\n",
    "    :return: Тензор изображения в формате BGR с нормализацией.\n",
    "    \"\"\"\n",
    "    np_img = np.array(pil_rgb_image)\n",
    "    bgr_img = np_img[:, :, ::-1]  # Преобразование RGB -> BGR\n",
    "    bgr_img_norm = (bgr_img / 255.0 - 0.5) / 0.5  # Нормализация\n",
    "    tensor = torch.tensor(bgr_img_norm.transpose(2, 0, 1), dtype=torch.float32)\n",
    "    \n",
    "    return tensor.unsqueeze(0)  # Добавление размерности батча"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование тензора  в изображение PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_output(tensor: torch.Tensor) -> Image.Image:\n",
    "    tensor = tensor.squeeze(0).cpu().numpy()\n",
    "    bgr_img = (tensor * 0.5 + 0.5) * 255.0\n",
    "    bgr_img = bgr_img.transpose(1, 2, 0).astype(np.uint8)\n",
    "    rgb_img = bgr_img[:, :, ::-1]\n",
    "    return Image.fromarray(rgb_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset для тестовых пар"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPairsDataset(Dataset):\n",
    "    \"\"\"Датасет для тестирования пар предварительно выровненных изображений.\n",
    "    \n",
    "    Attributes:\n",
    "        test_dir: Путь к директории с тестовыми данными\n",
    "        pair_ids: Отсортированный список идентификаторов пар изображений\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, test_dir: str) -> None:\n",
    "        self.test_dir = Path(test_dir)\n",
    "        self.pair_ids = sorted(os.listdir(self.test_dir))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Возвращает общее количество пар изображений.\"\"\"\n",
    "        return len(self.pair_ids)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[str, Tensor, Tensor]:\n",
    "        \"\"\"Загружает и предобрабатывает пару изображений.\n",
    "        \n",
    "        Args:\n",
    "            idx: Индекс пары изображений в датасете\n",
    "            \n",
    "        Returns:\n",
    "            Кортеж с:\n",
    "            - идентификатором пары\n",
    "            - тензор первого изображения\n",
    "            - тензор второго изображения\n",
    "        \"\"\"\n",
    "        pair_id = self.pair_ids[idx]\n",
    "        pair_path = self.test_dir / pair_id\n",
    "        \n",
    "        # Загрузка и преобразование изображений\n",
    "        img0 = self._load_image(pair_path / \"0.jpg\")\n",
    "        img1 = self._load_image(pair_path / \"1.jpg\")\n",
    "        \n",
    "        return pair_id, img0, img1\n",
    "\n",
    "    def _load_image(self, path: Path) -> Tensor:\n",
    "        \"\"\"Внутренний метод для загрузки и преобразования изображения.\"\"\"\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        tensor = to_input(image).squeeze(0)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание датасета из пар изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество изображений в тестовом датасете: 9\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestPairsDataset(test_dir)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(f\"Количество изображений в тестовом датасете: {len(test_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSM атака"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для FGSM атаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(\n",
    "    image: Tensor,\n",
    "    epsilon: float,\n",
    "    data_grad: Tensor,\n",
    ") -> Tensor:\n",
    "    \"\"\"Реализация атаки Fast Gradient Sign Method (FGSM).\n",
    "    \n",
    "    Args:\n",
    "        image: Исходный тензор изображения (формата [C, H, W])\n",
    "        epsilon: Коэффициент силы атаки (максимальное отклонение пикселя)\n",
    "        data_grad: Градиенты loss по входным данным\n",
    "    \n",
    "    Returns:\n",
    "        Tensor: Возмущенное изображение с ограниченными значениями [0, 1]\n",
    "    \"\"\"\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0.0, 1.0)\n",
    "    \n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание датасета с FGSM атакой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(\n",
    "    test_dataset: Iterable[Tuple[str, torch.Tensor, torch.Tensor]],\n",
    "    device: torch.device,\n",
    "    model: torch.nn.Module,\n",
    "    fgsm_attack: Callable[[torch.Tensor, float, torch.Tensor], torch.Tensor],\n",
    "    to_output: Callable[[torch.Tensor], Any],\n",
    "    images_dir: str,\n",
    "    check_attack_score_dir: str,\n",
    "    epsilon: float = 1.5,\n",
    ") -> None:\n",
    "\n",
    "    for folder, tensor0, tensor1 in test_dataset:\n",
    "        tensor0 = F.interpolate(\n",
    "            tensor0.unsqueeze(0), size=(112, 112),\n",
    "            mode='bilinear', align_corners=False\n",
    "        ).to(device)\n",
    "        tensor1 = F.interpolate(\n",
    "            tensor1.unsqueeze(0), size=(112, 112),\n",
    "            mode='bilinear', align_corners=False\n",
    "        ).to(device).detach()\n",
    "        tensor1.requires_grad = True\n",
    "\n",
    "        emb0, _ = model(tensor0)\n",
    "        emb1, _ = model(tensor1)\n",
    "\n",
    "        emb0 = F.normalize(emb0, p=2, dim=1)\n",
    "        emb1 = F.normalize(emb1, p=2, dim=1)\n",
    "\n",
    "        sims = torch.sum(emb0 * emb1, dim=1)\n",
    "        loss = -sims.mean()\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        perturbed_image = fgsm_attack(tensor1, epsilon, tensor1.grad.data)\n",
    "        img = to_output(perturbed_image.detach())\n",
    "        perturbed_embedding, _ = model(perturbed_image)\n",
    "        perturbed_embedding = F.normalize(perturbed_embedding, p=2, dim=1)\n",
    "        sims_new = torch.sum(emb0 * perturbed_embedding, dim=1)\n",
    "\n",
    "        target_folder = os.path.join(check_attack_score_dir, folder)\n",
    "        os.makedirs(target_folder, exist_ok=True)\n",
    "        shutil.copy(\n",
    "            os.path.join(images_dir, folder, \"0.jpg\"),\n",
    "            os.path.join(target_folder, \"0.jpg\")\n",
    "        )\n",
    "        img.save(os.path.join(target_folder, \"9.jpg\"))\n",
    "\n",
    "process_dataset(test_dataset, device, model, fgsm_attack, to_output, images_dir=IMAGE_DATASET_DIR, check_attack_score_dir=FGSM_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
